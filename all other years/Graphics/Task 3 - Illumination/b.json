{"camera":{"position":[5.354512874778072,3.941521935422117,25.012066796336605],"target":[0,0,0],"nearClipping":0.1,"farClipping":1000,"projection":"Perspective","perspectiveFov":45,"orthographicFov":30},"model":{"mesh":"teapot","position":[0,-8,0],"rotationAxis":[1,0,0],"rotationAngle":-90,"scale":[1,1,1],"depthTest":"LESS","faceCulling":"","frontFace":"CCW","showWireframe":false},"passes":{"Model":{"base":{"shaders":{"vertex":{"source":"//vertex position in world coordinates\nattribute vec3 vertex_worldSpace;\n//surface normal at the vertex in world coordinates\nattribute vec3 normal_worldSpace;\n//texture coordinates at that vertex\nattribute vec2 textureCoordinate_input;\n\n//model Matrix (Identity in our case)\nuniform mat4 mMatrix;\n//view Matrix\nuniform mat4 vMatrix;\n//projection Matrix\nuniform mat4 pMatrix;\n\nvarying vec4 vertex_camSpace;\nvarying vec3 N;\n\nvoid main() {\n  vertex_camSpace = vMatrix * mMatrix * vec4(vertex_worldSpace, 1.0);\n  gl_Position = pMatrix * vertex_camSpace;\n\n  // Compute the normal in the camera space\n  N = normalize(vec3(vMatrix * mMatrix * vec4(normal_worldSpace, 0.0)));\n}"},"fragment":{"source":"#define PI 3.1415926535897932384626433832795\n\n//for better performance less precision\nprecision mediump float;\n\nuniform vec4 k_ambient;\nuniform vec4 k_diffuse;\nuniform vec4 k_specular;\nuniform float shininess;\n\nuniform vec3 light_camSpace;\n\nuniform float phi_s;\n\nvarying vec4 vertex_camSpace;\nvarying vec3 N;\n\n//main program for each fragment = pixel candidate\nvoid main() {\n// Compute the light vector in the camera space\n  vec3 L = normalize(light_camSpace - vec3(vertex_camSpace));\n\n  // Compute the view vector in the camera space, which is the same as the\n  // light vector since the light and the view point are in the same point\n  vec3 V = L;\n\n  float N_times_L = max(dot(N, L), 0.0);\n\n  // Compute the reflacted vector in the camera space\n  vec3 R = 2. * N_times_L * N - L;\n\n  float V_TIMES_R = max(dot(V, R), 0.0);\n\n  // Compute the distance between view point and the vertex\n  float D = length(vec3(vertex_camSpace));\n\n  float diffuse = N_times_L;\n\n  float specular = pow(V_TIMES_R, shininess);\n\n  // Compute the final colour which take account of the ambient, diffuse and specular parameters\n  gl_FragColor = k_ambient + (k_diffuse * diffuse + k_specular * specular) * phi_s / (4.0 * PI * D * D);\n}"}},"uniforms":{"value":{"mMatrix":{"attachment":"Model Matrix"},"vMatrix":{"attachment":"View Matrix"},"pMatrix":{"attachment":"Projection Matrix"},"k_ambient":{"value":[0.5,0,0,1]},"k_diffuse":{"value":[1,0,0,1]},"k_specular":{"value":[1,1,1,1]},"shininess":{"value":[10]},"light_camSpace":{"value":[0,0,0]},"phi_s":{"value":[2000]}}}}},"Quad":{"R2T":{"shaders":{"vertex":{"source":"//vertex coordinates in world space for the render quad\nattribute vec3 vertex_worldSpace;\n//texture coordinate for this vertex and the render quad\nattribute vec2 textureCoordinate_input;\n\n//texture coordinate needs to be passed on to the R2T fragment shader\nvarying vec2 varyingTextureCoordinate;\n\n//main program for each vertex of the render quad\nvoid main() {\n  gl_Position = vec4(vertex_worldSpace, 1.0);\n  varyingTextureCoordinate = textureCoordinate_input;\n}"},"fragment":{"source":"precision mediump float;\n\n//a texture sampling unit, which is bound to the render quad texture buffer\nuniform sampler2D textureRendered;\n\n//texture coordinates coming from the vertex shader, interpolated through the rasterizer\nvarying vec2 varyingTextureCoordinate;\n\n//main program for each fragment of the render quad\nvoid main() {\n  gl_FragColor = texture2D(textureRendered, varyingTextureCoordinate.st);\n}"}},"uniforms":{"value":{"textureRendered":{"attachment":"Model/base Pass color"}}}}}},"output":{"image":"Quad/R2T Pass color"}}